{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "autoencoder-train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abel-bernabeu/autoencoder/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKr9CMXqSDj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "outputId": "47f48f9a-42ee-4e14-b45d-91b39db565eb"
      },
      "source": [
        "!rm runs -rf\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 14426), started 1:23:07 ago. (Use '!kill 14426' to kill it.)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f07e5685978>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"800\"\n",
              "            src=\"http://localhost:6006\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UybQQ57Dia_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size': 4,\n",
        "    'device': 'cuda',\n",
        "    'max_dataset_size': 100,\n",
        "    'train_dataset_size': 50,\n",
        "    'test_dataset_size': 50,\n",
        "    'log_interval': 2,\n",
        "    'num_epochs': 100,\n",
        "    'num_workers': 4,\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EXszz0fSDkK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "092ebd6d-ab8f-49a8-d490-e53fd4640ab8"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision.utils\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import autoencoder.datasets\n",
        "import autoencoder.transforms\n",
        "import autoencoder.models\n",
        "import datetime"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEuC5t4iM_CC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = SummaryWriter('')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg_XBWvRCE2y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49e6b5da-b45a-4a41-ce75-ea72e4a128b3"
      },
      "source": [
        "crops = autoencoder.datasets.CropsDataset(\"./data/image_dataset_part-a\", 224, 224, subset_size=hparams['max_dataset_size'], assume_fixed_size=False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sizes from images in ./data/image_dataset_part-a: 100%|██████████| 100/100 [00:00<00:00, 9188.56it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1IKGDMxCOGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show a few crops\n",
        "few_crops = [ transforms.ToTensor()(crop[0]) for crop in [crops[index] for index in range(16)]]\n",
        "grid = torchvision.utils.make_grid(few_crops, nrow=4)\n",
        "writer.add_image(\"1) a few crops\", grid)\n",
        "writer.flush()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaXiCozCEzB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Random split in train and test sets\n",
        "train_crops, test_crops = torch.utils.data.random_split(crops, [hparams['train_dataset_size'], hparams['test_dataset_size'],])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0klioFh4t_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corruption = autoencoder.transforms.ConvertToGray()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa1PTuo_Bc9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input_transform = transforms.Compose([\n",
        "  corruption,\n",
        "  transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_output_transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_xydims_samples = autoencoder.datasets.XYDimsDataset(train_crops, train_input_transform, train_output_transform)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5Rlhxt2SaaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show x from a few train samples\n",
        "few_train_x = [ sample[0] for sample in [train_xydims_samples[index] for index in range(4)] ]\n",
        "grid = torchvision.utils.make_grid(few_train_x, nrow=4)\n",
        "writer.add_image(\"2) x from a few train samples\", grid)\n",
        "writer.flush()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm1qG67AUQx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show y from a few train samples\n",
        "few_train_y = [ sample[1] for sample in [train_xydims_samples[index] for index in range(4)] ]\n",
        "grid = torchvision.utils.make_grid(few_train_y, nrow=4)\n",
        "writer.add_image(\"3) y from a few train samples\", grid)\n",
        "writer.flush()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "995Re_8_QU2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_input_transform = transforms.Compose([\n",
        "  corruption,\n",
        "  transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_output_transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "test_xydims_samples = autoencoder.datasets.XYDimsDataset(test_crops, test_input_transform, test_output_transform)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4s-iajLXh6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show x from a few test samples\n",
        "few_test_x = [ sample[0] for sample in [test_xydims_samples[index] for index in range(4)] ]\n",
        "grid = torchvision.utils.make_grid(few_test_x, nrow=4)\n",
        "writer.add_image(\"4) x from a few test samples\", grid)\n",
        "writer.flush()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIjvMjs-Xrry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show y from a few train samples\n",
        "few_test_y = [ sample[1] for sample in [test_xydims_samples[index] for index in range(4)] ]\n",
        "grid = torchvision.utils.make_grid(few_test_y, nrow=4)\n",
        "writer.add_image(\"5) y from a few test samples\", grid)\n",
        "writer.flush()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MxSoKSUnXgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_xydims_samples, batch_size=hparams['batch_size'], shuffle=True, num_workers=hparams['num_workers'])\n",
        "test_loader = torch.utils.data.DataLoader(test_xydims_samples, batch_size=hparams['batch_size'], shuffle=False, num_workers=hparams['num_workers'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOW0NNlhfHA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(train_loader, model, optimizer, criterion, hparams):\n",
        "    np.random.seed(datetime.datetime.now().microsecond)\n",
        "    model.train()\n",
        "    device = hparams['device']\n",
        "    losses = []\n",
        "    for data, target, _, _ in train_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    return np.mean(losses)\n",
        "\n",
        "def test_epoch(test_loader, model, criterion, hparams):\n",
        "    np.random.seed(0)\n",
        "    model.eval()\n",
        "    device = hparams['device']\n",
        "    eval_losses = []\n",
        "    with torch.no_grad():\n",
        "        for data, target, _, _ in test_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            output = model(data)\n",
        "            eval_losses.append(criterion(output, target).item())\n",
        "    return np.mean(eval_losses)\n",
        "\n",
        "def inference(model, inputs_list):\n",
        "    \"\"\"\n",
        "    Do an inference with the model for each input tensor from the provided list and\n",
        "    return a list with the inference results\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for x in inputs_list:\n",
        "        num_channels = x.shape[0]\n",
        "        height = x.shape[1]\n",
        "        width = x.shape[2]\n",
        "        single_element_batch = x.clone().detach().reshape(1, num_channels, height, width)\n",
        "        single_element_batch = single_element_batch.to(hparams['device'])\n",
        "        model.to(hparams['device'])\n",
        "        model.eval()\n",
        "        output = model(single_element_batch)\n",
        "        output = output.reshape(num_channels, height, width)\n",
        "        result.append(output)\n",
        "    return result"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFiW6iqoWmZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Autoencoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, padding_mode='replicate'),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.upsample = nn.Sequential(\n",
        "            nn.ConvTranspose2d(32, 3, kernel_size=3, stride=1, padding=1, output_padding=0),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.upsample(x)\n",
        "        return x"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7U6yTCe7xqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Move few_test_x to the same device where the inferences will be left\n",
        "for index in range(len(few_test_x)):\n",
        "    few_test_x[index] = few_test_x[index].to(hparams['device'])\n",
        "\n",
        "# Move few_test_x to the same device where the inferences will be left\n",
        "for index in range(len(few_train_x)):\n",
        "    few_train_x[index] = few_train_x[index].to(hparams['device'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-TS737bhbTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Autoencoder()\n",
        "model.to(hparams['device'])\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), weight_decay=1e-4)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "num_epochs = hparams['num_epochs']\n",
        "\n",
        "try:\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        train_loss = train_epoch(train_loader, model, optimizer, criterion, hparams)\n",
        "\n",
        "        test_loss = test_epoch(test_loader, model, criterion, hparams)\n",
        "\n",
        "        writer.add_scalar(\"train loss\", train_loss, global_step=epoch)\n",
        "\n",
        "        writer.add_scalar(\"test loss\", test_loss, global_step=epoch)\n",
        "\n",
        "        # Show inferences with a few training samples\n",
        "        few_train_y = inference(model, few_train_x)\n",
        "        grid = torchvision.utils.make_grid(few_train_x + few_train_y, nrow=4)\n",
        "        writer.add_image( str(6+2*epoch) + \") EPOCH \" + str(epoch)  + \": y from a few train samples\", grid)\n",
        "\n",
        "        # Show inferences with a few test samples\n",
        "        few_test_y = inference(model, few_test_x)\n",
        "        grid = torchvision.utils.make_grid(few_test_x + few_test_y, nrow=4)\n",
        "        writer.add_image( str(6+2*epoch+1) + \") EPOCH \" + str(epoch) + \": y from a few test samples\", grid)\n",
        "\n",
        "        writer.flush()\n",
        "        \n",
        "except KeyboardInterrupt:\n",
        "\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XnXtXHZfSVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer.close()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSf7uf0o5KfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}