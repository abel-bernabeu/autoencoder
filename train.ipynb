{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/abel-bernabeu/autoencoder/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 873
    },
    "colab_type": "code",
    "id": "AKr9CMXqSDj2",
    "outputId": "b86b9a8f-3873-466d-c125-e5c04c664044"
   },
   "outputs": [],
   "source": [
    "# Launch Tensorboard\n",
    "#!rm runs -rf # Uncomment to delete all the previous Tensorboard runs\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for training checkpoints\n",
    "#!rm params -rf # Uncomment to delete all the checkpoints\n",
    "%mkdir -p params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UybQQ57Dia_E"
   },
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'batch_size': 8,\n",
    "    'device': 'cuda',\n",
    "    'max_dataset_size': 20,\n",
    "    'train_dataset_size':10,\n",
    "    'test_dataset_size': 10,\n",
    "    'num_epochs': 1000,\n",
    "    'num_workers': 4,\n",
    "    'params' : \"./params/colorizer.pt\",\n",
    "    'continue_with_best_model' : False,\n",
    "    'checkpointing_freq' : 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5EXszz0fSDkK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.utils\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import autoencoder.datasets\n",
    "import autoencoder.transforms\n",
    "import autoencoder.models\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AEuC5t4iM_CC"
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lg_XBWvRCE2y"
   },
   "outputs": [],
   "source": [
    "crops = autoencoder.datasets.CropsDataset(\"./data/image_dataset_part-a\", 224, 224, subset_size=hparams['max_dataset_size'], assume_fixed_size=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1IKGDMxCOGL"
   },
   "outputs": [],
   "source": [
    "# Show a few crops\n",
    "few_crops = [ transforms.ToTensor()(crop[0]) for crop in [crops[index] for index in range(16)]]\n",
    "grid = torchvision.utils.make_grid(few_crops, nrow=4)\n",
    "writer.add_image(\"1) a few crops\", grid)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NaXiCozCEzB0"
   },
   "outputs": [],
   "source": [
    "# Random split in train and test sets\n",
    "train_crops, test_crops = torch.utils.data.random_split(crops, [hparams['train_dataset_size'], hparams['test_dataset_size'],])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M0klioFh4t_7"
   },
   "outputs": [],
   "source": [
    "corruption = autoencoder.transforms.ConvertToGray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qa1PTuo_Bc9n"
   },
   "outputs": [],
   "source": [
    "train_input_transform = transforms.Compose([\n",
    "  corruption,\n",
    "  transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_output_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_xydims_samples = autoencoder.datasets.XYDimsDataset(train_input_transform, train_output_transform, dataset=train_crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5Rlhxt2SaaX"
   },
   "outputs": [],
   "source": [
    "# Show x from a few train samples\n",
    "few_train_x = [ sample[0] for sample in [train_xydims_samples[index] for index in range(4)] ]\n",
    "grid = torchvision.utils.make_grid(few_train_x, nrow=4)\n",
    "writer.add_image(\"2) x from a few train samples\", grid)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qm1qG67AUQx3"
   },
   "outputs": [],
   "source": [
    "# Show y from a few train samples\n",
    "few_train_y = [ sample[1] for sample in [train_xydims_samples[index] for index in range(4)] ]\n",
    "grid = torchvision.utils.make_grid(few_train_y, nrow=4)\n",
    "writer.add_image(\"3) y from a few train samples\", grid)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "995Re_8_QU2g"
   },
   "outputs": [],
   "source": [
    "test_input_transform = transforms.Compose([\n",
    "  corruption,\n",
    "  transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_output_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "test_xydims_samples = autoencoder.datasets.XYDimsDataset(test_input_transform, test_output_transform, dataset=test_crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F4s-iajLXh6u"
   },
   "outputs": [],
   "source": [
    "# Show x from a few test samples\n",
    "few_test_x = [ sample[0] for sample in [test_xydims_samples[index] for index in range(4)] ]\n",
    "grid = torchvision.utils.make_grid(few_test_x, nrow=4)\n",
    "writer.add_image(\"4) x from a few test samples\", grid)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wIjvMjs-Xrry"
   },
   "outputs": [],
   "source": [
    "# Show y from a few train samples\n",
    "few_test_y = [ sample[1] for sample in [test_xydims_samples[index] for index in range(4)] ]\n",
    "grid = torchvision.utils.make_grid(few_test_y, nrow=4)\n",
    "writer.add_image(\"5) y from a few test samples\", grid)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-MxSoKSUnXgS"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_xydims_samples, batch_size=hparams['batch_size'], shuffle=True, num_workers=hparams['num_workers'])\n",
    "test_loader = torch.utils.data.DataLoader(test_xydims_samples, batch_size=hparams['batch_size'], shuffle=False, num_workers=hparams['num_workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jOW0NNlhfHA5"
   },
   "outputs": [],
   "source": [
    "def train_epoch(train_loader, model, optimizer, criterion, hparams):\n",
    "    np.random.seed(datetime.datetime.now().microsecond)\n",
    "    model.train()\n",
    "    device = hparams['device']\n",
    "    losses = []\n",
    "    for data, target, _, _ in train_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    return np.mean(losses)\n",
    "\n",
    "def test_epoch(test_loader, model, criterion, hparams):\n",
    "    np.random.seed(0)\n",
    "    model.eval()\n",
    "    device = hparams['device']\n",
    "    eval_losses = []\n",
    "    with torch.no_grad():\n",
    "        for data, target, _, _ in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            eval_losses.append(criterion(output, target).item())\n",
    "    return np.mean(eval_losses)\n",
    "\n",
    "def inference(model, inputs_list):\n",
    "    \"\"\"\n",
    "    Do an inference with the model for each input tensor from the provided list and\n",
    "    return a list with the inference results\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for x in inputs_list:\n",
    "        num_channels = x.shape[0]\n",
    "        height = x.shape[1]\n",
    "        width = x.shape[2]\n",
    "        single_element_batch = x.clone().detach().reshape(1, num_channels, height, width)\n",
    "        single_element_batch = single_element_batch.to(hparams['device'])\n",
    "        model.to(hparams['device'])\n",
    "        model.eval()\n",
    "        output = model(single_element_batch)\n",
    "        output = output.reshape(num_channels, height, width)\n",
    "        result.append(output)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iFiW6iqoWmZs"
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, padding_mode='replicate'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, padding_mode='replicate'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),            \n",
    "            nn.Conv2d(64, 3, kernel_size=1, stride=1, padding=0),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = (x + 1) * 0.5\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7U6yTCe7xqe"
   },
   "outputs": [],
   "source": [
    "# Move few_test_x to the same device where the inferences will be left\n",
    "for index in range(len(few_test_x)):\n",
    "  few_test_x[index] = few_test_x[index].to(hparams['device'])\n",
    "\n",
    "# Move few_test_y to the same device where the inferences will be left\n",
    "for index in range(len(few_train_y)):\n",
    "  few_train_y[index] = few_train_y[index].to(hparams['device'])\n",
    "\n",
    "# Move few_train_x to the same device where the inferences will be left\n",
    "for index in range(len(few_train_x)):\n",
    "  few_train_x[index] = few_train_x[index].to(hparams['device'])\n",
    "\n",
    "# Move few_train_y to the same device where the inferences will be left\n",
    "for index in range(len(few_test_y)):\n",
    "  few_test_y[index] = few_test_y[index].to(hparams['device'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model, optimer and loss\n",
    "model = Autoencoder()\n",
    "optimizer = optim.Adam(model.parameters(), weight_decay=1e-4)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to device\n",
    "model = model.to(hparams['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-TS737bhbTg"
   },
   "outputs": [],
   "source": [
    "# Restore model and optimizer from previous checkpoint or create new checkpoint from scratch\n",
    "if os.path.isfile(hparams['params']):\n",
    "    print(\"Restoring from previous checkpoint\")\n",
    "    checkpoint = torch.load(hparams['params'])    \n",
    "    if hparams['continue_with_best_model']:\n",
    "        model.load_state_dict(checkpoint['best_model'])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint['last_model'])        \n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "else:\n",
    "    next_epoch = 0\n",
    "    best_model_params = model.state_dict()\n",
    "    checkpoint = {\n",
    "        'epoch' : 0,\n",
    "        'best_train_loss': None,\n",
    "        'best_model': model.state_dict(),\n",
    "        'last_model': model.state_dict(),\n",
    "        'optimizer' : optimizer.state_dict()\n",
    "    }\n",
    "\n",
    "# Run a number of training epochs\n",
    "start = checkpoint['epoch']\n",
    "end = hparams['num_epochs']\n",
    "\n",
    "if start < end - 1 or checkpoint['best_train_loss'] is None:\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(start, end):\n",
    "\n",
    "            train_loss = train_epoch(train_loader, model, optimizer, criterion, hparams)\n",
    "            \n",
    "            test_loss = test_epoch(test_loader, model, criterion, hparams)            \n",
    "\n",
    "            if epoch == hparams['num_epochs'] - 1 or epoch % hparams['checkpointing_freq'] == 0:\n",
    "\n",
    "                print('Saving checkpoint for epoch ' + str(epoch))\n",
    "                checkpoint['epoch'] = epoch\n",
    "\n",
    "                if checkpoint['best_train_loss'] is None or train_loss < checkpoint['best_train_loss']:\n",
    "                    print('New best model found!')                \n",
    "                    checkpoint['best_train_loss'] = train_loss\n",
    "                    checkpoint['best_model'] = model.state_dict()\n",
    "\n",
    "                checkpoint['last_model'] = model.state_dict()\n",
    "\n",
    "                checkpoint['optimizer'] = optimizer.state_dict()\n",
    "                \n",
    "                torch.save(checkpoint, hparams['params'])\n",
    "\n",
    "            writer.add_scalar(\"train loss\", train_loss, global_step=epoch)\n",
    "                        \n",
    "            writer.add_scalar(\"test loss\", test_loss, global_step=epoch)\n",
    "\n",
    "            # Show inferences with a few training samples\n",
    "            few_train_y_hat = inference(model, few_train_x)\n",
    "            grid = torchvision.utils.make_grid(few_train_y + few_train_x + few_train_y_hat, nrow=4)\n",
    "            writer.add_image(\"a few train samples, one column per sample in (y, x, y_hat) format\", grid, global_step=epoch)\n",
    "\n",
    "            # Show inferences with a few test samples\n",
    "            few_test_y_hat = inference(model, few_test_x)\n",
    "            grid = torchvision.utils.make_grid(few_test_y + few_test_x + few_test_y_hat, nrow=4)\n",
    "            writer.add_image(\"a few test samples, one column per sample in (y, x, y_hat) format\", grid, global_step=epoch)\n",
    "\n",
    "            writer.flush()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "\n",
    "        print('Exiting from training early')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6XnXtXHZfSVe"
   },
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "autoencoder-train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
