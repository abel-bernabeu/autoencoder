{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "compressor_train.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abel-bernabeu/autoencoder/blob/master/compressor_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myODRbvAf3EK",
        "colab_type": "text"
      },
      "source": [
        "# Description\n",
        "\n",
        "This notebook is an implementation of the enconder/decoder deep learning architecture from \"Lossy image compression with compression autoencoders\", by \n",
        "Lucas Theis, Wenzhe Shi, Andrew Cunningham & Ferenc Husz, published in 2017\n",
        "(https://arxiv.org/pdf/1703.00395v1.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiB2DKaId1qC",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vInFoZlBd8o1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the dataset if needed\n",
        "import os.path\n",
        "if not os.path.isdir('./data'):\n",
        "    !rm  -rf image_dataset_part-a.zip\n",
        "    !mkdir data -p\n",
        "    !cd data ; wget https://www.dropbox.com/s/91rpg5dqkhhhkzu/image_dataset_part-a.zip\n",
        "    !cd data ; unzip -q image_dataset_part-a.zip\n",
        "\n",
        "# Get the latest source code if needed\n",
        "if not os.path.isdir('./autoencoder'):\n",
        "    !wget https://www.dropbox.com/s/jfu0ksttohnklkq/autoencoder-master.zip && \\\n",
        "    unzip -q autoencoder-master.zip && \\\n",
        "    mv autoencoder-master/autoencoder/ . && \\\n",
        "    rm autoencoder-master -rf\n",
        "\n",
        "if not os.path.isdir('./share'):\n",
        "    try:\n",
        "        # Try to mount share from Google Drive when on Collab\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive/')\n",
        "        !ln -s  /content/drive/My\\ Drive/archive/2020/aidl/ share\n",
        "    except:\n",
        "        # The fallback for when not in Collab is to download share from Dropbox\n",
        "        !wget https://www.dropbox.com/s/76w9gsga8mz5ve4/share.tgz && tar xzvf share.tgz\n",
        "\n",
        "# Create the model directories (if they do not already exist)\n",
        "!mkdir -p share/twitter-compressor\n",
        "!mkdir -p share/sparse-twitter-compressor\n",
        "!mkdir -p share/uniform-quant-twitter-compressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAJ1smCz1y0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import autoencoder.models\n",
        "import autoencoder.utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGvOW4eo2S7Y",
        "colab_type": "text"
      },
      "source": [
        "# Baseline model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi0IGZoiE-CA",
        "colab_type": "text"
      },
      "source": [
        "Our baseline model effort focuses on training the proposed neural network with the maximum possible accuracy, but not investing any effort in quantization or entropic coding of the features.\n",
        "\n",
        "This model only achieves a 50% compression when the input is in Float32 but it is used for three purposes:\n",
        "\n",
        "- prove that the input can be reconstructed accurately with the kind of neural network that is proposed in the paper.\n",
        "\n",
        "- set an upper bound on accuracy (**43 db**)\n",
        "\n",
        "- give an estimation of how long it takes to train a state of the art compression model (**4 days on a Tesla P100**)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWvnxFWQlPiY",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdAi7hZDf3EO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 32,\n",
        "    'lr' : 1e-3,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 128,\n",
        "    'block_height' : 128,\n",
        "    'train_dataset_size' : 5000,\n",
        "    'test_dataset_size' : 500,\n",
        "    'num_epochs' : 12577,\n",
        "    'num_workers' : 4,\n",
        "    'params' : \"share/twitter-compressor/model.pt\",\n",
        "    'continue_with_best_model' : False,\n",
        "    'tensorboard_runs' : 'share/twitter-compressor/runs/',\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 20,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntf1Z4_Yf3Eg",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3OKn6N3TbJ84",
        "colab": {}
      },
      "source": [
        "class TwitterEncoder(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_state_num_channels = 96):\n",
        "        super(TwitterEncoder, self).__init__()\n",
        "\n",
        "        self.hidden_state_num_channels = hidden_state_num_channels\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=5, stride=2, padding=2, padding_mode='replicate'),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU())\n",
        "  \n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2, padding_mode='replicate'),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU())\n",
        "\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, padding_mode='replicate'),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU())\n",
        "\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, padding_mode='replicate'),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU())\n",
        "\n",
        "        self.block5 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, padding_mode='replicate'),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU())\n",
        "\n",
        "        self.block6 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, padding_mode='replicate'),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU())\n",
        "\n",
        "        self.block7 = nn.Sequential(\n",
        "            nn.Conv2d(128, self.hidden_state_num_channels, kernel_size=5, stride=2, padding=2, padding_mode='replicate'))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x) + x\n",
        "        x = self.block4(x) + x\n",
        "        x = self.block5(x) + x\n",
        "        x = self.block6(x) + x\n",
        "        x = self.block7(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TwitterDecoder(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_state_num_channels = 96):\n",
        "        super(TwitterDecoder, self).__init__()\n",
        "\n",
        "        self.hidden_state_num_channels = hidden_state_num_channels\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(self.hidden_state_num_channels, 512*4, kernel_size=3, stride=1, padding=1, padding_mode='replicate'),\n",
        "            nn.PixelShuffle(2),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU())\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(512, 128, kernel_size=3, stride=1, padding=1, padding_mode='replicate'),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU())\n",
        "\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, padding_mode='replicate'),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU())\n",
        "\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, padding_mode='replicate'),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU())\n",
        "\n",
        "        self.block5 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, padding_mode='replicate'),\n",
        "            nn.BatchNorm2d(128),                        \n",
        "            nn.LeakyReLU())\n",
        "\n",
        "        self.block6 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256*4, kernel_size=3, stride=1, padding=1, padding_mode='replicate'),\n",
        "            nn.PixelShuffle(2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU())\n",
        "\n",
        "        self.block7 = nn.Sequential(\n",
        "            nn.Conv2d(256, 3*4, kernel_size=3, stride=1, padding=1, padding_mode='replicate'),\n",
        "            nn.PixelShuffle(2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x) \n",
        "        x = self.block3(x) + x\n",
        "        x = self.block4(x) + x\n",
        "        x = self.block5(x) + x\n",
        "        x = self.block6(x)\n",
        "        x = self.block7(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TwitterCompressor(autoencoder.models.CompressionAutoencoder):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(autoencoder.models.CompressionAutoencoder, self).__init__()\n",
        "        self.encoder = TwitterEncoder()\n",
        "        self.decoder = TwitterDecoder()\n",
        "\n",
        "\n",
        "model = TwitterCompressor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysBd-c-DlYA8",
        "colab_type": "text"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AKr9CMXqSDj2",
        "colab": {}
      },
      "source": [
        "# Launch TensorBoard\n",
        "#%load_ext tensorboard\n",
        "#%tensorboard --logdir share/twitter-compressor/runs/ --port 6101"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THBPV92Kf3Ex",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXbtDD_PqYcm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cyzSi8YlnvG",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jOW0NNlhfHA5",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=model, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UynFM6TYEL12",
        "colab_type": "text"
      },
      "source": [
        "# Increased sparsity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJEvb7N22tNR",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xBTpKybm2yAp",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 40,\n",
        "    'lr' : 1e-6,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 224,\n",
        "    'block_height' : 224,\n",
        "    'hidden_state_num_channels' : 48,\n",
        "    'train_dataset_size' : 1000,\n",
        "    'test_dataset_size' : 500,\n",
        "    'num_epochs' : 16000,\n",
        "    'num_workers' : 4,\n",
        "    'params' : \"share/sparse-twitter-compressor/model.pt\",\n",
        "    'continue_with_best_model' : False,\n",
        "    'tensorboard_runs' : 'share/sparse-twitter-compressor/runs/',\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 20,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aE-Rr3v2pdD",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW_nmDLzGj0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SparseTwitterCompressor(autoencoder.models.CompressionAutoencoder):\n",
        "\n",
        "    def __init__(self, hidden_state_num_channels= hparams['hidden_state_num_channels']):\n",
        "        super(SparseTwitterCompressor, self).__init__()\n",
        "        self.encoder = TwitterEncoder(hidden_state_num_channels=hidden_state_num_channels)\n",
        "        self.decoder = TwitterDecoder(hidden_state_num_channels=hidden_state_num_channels)\n",
        "\n",
        "model = SparseTwitterCompressor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtxmt1Lv4wBl",
        "colab_type": "text"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sxUAGmi43tT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Launch TensorBoard\n",
        "#%load_ext tensorboard\n",
        "#%tensorboard --logdir share/sparse-twitter-compressor/runs/ --port 6200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0wePJAW5bpC",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0Fv9Pdr5d4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deyZjDZx5jfa",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCm6ZWG05exL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=model, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fRgc18irGJDk"
      },
      "source": [
        "# Uniform quantization to 3 bits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BvXFvg6JGJEC"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MmoCLvQAGJEG",
        "colab": {}
      },
      "source": [
        "hparams = {\n",
        "    'batch_size' : 40,\n",
        "    'lr' : 1e-6,\n",
        "    'device' : 'cuda',\n",
        "    'block_width' : 224,\n",
        "    'block_height' : 224,\n",
        "    'train_dataset_size' : 1000,\n",
        "    'test_dataset_size' : 500,\n",
        "    'num_epochs' : 20000,\n",
        "    'num_workers' : 4,\n",
        "    'params' : \"share/uniform-quant-twitter-compressor/model.pt\",\n",
        "    'continue_with_best_model' : False,\n",
        "    'tensorboard_runs' : 'share/uniform-quant-twitter-compressor/runs/',\n",
        "    'checkpointing_freq' : 10,\n",
        "    'inference_freq' : 20,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AFNQeJguGJEV"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OMSkESehGJEY",
        "colab": {}
      },
      "source": [
        "class QuantizingCompressionAutoencoder(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, num_bits):\n",
        "        super(QuantizingCompressionAutoencoder, self).__init__()\n",
        "        self.encoder = None\n",
        "        self.num_bits = num_bits\n",
        "        self.quantize = autoencoder.models.Quantize()\n",
        "        self.dequantize = autoencoder.models.Dequantize()\n",
        "        self.decoder = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "\n",
        "        batch_dim_index = 0\n",
        "        channels_dim_index = 1\n",
        "        rows_dim_index = 2\n",
        "        cols_dim_index = 3\n",
        "\n",
        "        batch = x.size()[batch_dim_index]\n",
        "        channels  = x.size()[channels_dim_index]\n",
        "        height = x.size()[rows_dim_index]\n",
        "        width  = x.size()[cols_dim_index]\n",
        "\n",
        "        per_channel_num_bits = self.num_bits * torch.ones(batch, self.encoder.hidden_state_num_channels).to(x.device)\n",
        "        hq, per_channel_min, per_channel_max, per_channel_num_bits = self.quantize(h, quantization_select = None, per_channel_num_bits = per_channel_num_bits)\n",
        "        hd = self.dequantize(hq, per_channel_min, per_channel_max, per_channel_num_bits)\n",
        "\n",
        "        y = self.decoder(hd)\n",
        "\n",
        "        yp = torch.nn.functional.hardtanh(y)\n",
        "\n",
        "        return (yp + 1) * 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i0pIrbbyGJEh",
        "colab": {}
      },
      "source": [
        "qmodel = QuantizingCompressionAutoencoder(num_bits=3)\n",
        "\n",
        "# Transfer learning from the non-quantized model\n",
        "qmodel.encoder = model.encoder\n",
        "qmodel.decoder = model.decoder\n",
        "\n",
        "# Freeze the encoder\n",
        "for param in qmodel.encoder.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sLqPM4SVGJEo"
      },
      "source": [
        "## TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q3__3I_RGJEq",
        "colab": {}
      },
      "source": [
        "# Launch TensorBoard\n",
        "#%load_ext tensorboard\n",
        "#%tensorboard --logdir share/uniform-quant-twitter-compressor/runs/ --port 6300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "26madMU5GJEu"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KuXcusPQGJEv",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, few_train_x, few_train_y, few_test_x, few_test_y = autoencoder.utils.create_dataloaders(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7a4-8S2zGJE1"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8fTNoEnPGJE3",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  autoencoder.utils.train(hparams=hparams, \\\n",
        "        model=qmodel, \\\n",
        "        train_loader=train_loader, \\\n",
        "        test_loader=test_loader, \\\n",
        "        few_train_x=few_train_x, few_train_y=few_train_y, \\\n",
        "        few_test_x=few_test_x, few_test_y=few_test_y)\n",
        "except KeyboardInterrupt:\n",
        "    print('Exiting from training early')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxcAT8eV6KGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}